## [Semester 6]

### [Data Science and Big Data Analytics Laboratory](https://github.com/RaniK27/University-Assignments/tree/main/Semester%206/DSBDAL)

| **Experiment Folder** | **Experiment Aim** |
|:---:|---|
| **[A1](#)** | **Data Wrangling I**<br>Perform the following operations using Python on any open source dataset (eg. data.csv)<br>1. Import all the required Python Libraries.<br>2. Locate an open source data from the web (eg. https://www.kaggle.com). Provide a clear description of the data and its source (i.e. URL of the web site).<br>3. Load the Dataset into pandas dataframe.<br>4. Data Preprocessing: check for missing values in the data using pandas isnull(), describe() function to get some initial statistics. Provide variable descriptions. Types of variables etc. Check the dimensions of the data frame.<br>5. Data Formatting and Data Normalization: Summarize the types of variables by checking the data types (i.e., character, numeric, integer, factor, and logical) of the variables in the data set. If variables are not in the correct data type, apply proper type conversions.<br>6. Turn categorical variables into quantitative variables in Python<br>In addition to the codes and outputs, explain every operation that you do in the above steps and explain everything that you do to import/read/scrape the data set. |
| **[A2](#)** | **Data Wrangling II**<br>Perform the following operations using Python on any open source dataset (eg. data.csv)<br>1. Scan all variables for missing values and inconsistencies. If there are missing values and/or inconsistencies, use any of the suitable techniques to deal with them.<br>2. Scan all numeric variables for outliers. If there are outliers, use any of the suitable techniques to deal with them.<br>3. Apply data transformations on at least one of the variables. The purpose of this transformation should be one of the following reasons: to change the scale for better understanding of the variable, to convert a non-linear relation into a linear one, or to decrease the skewness and convert the distribution into a normal distribution.<br>Reason and document your approach properly. |
| **[A3](#)** | **Basic Statistics - Measures of Central Tendencies and Variance**<br>Perform the following operations on any open source dataset (eg. data.csv)<br>1. Provide summary statistics (mean, median, minimum, maximum, standard deviation) for a dataset (age, income etc.) with numeric variables grouped by one of the qualitative (categorical) variable. For example, if your categorical variable is age groups and quantitative variable is income, then provide summary statistics of income grouped by the age groups. Create a list that contains a numeric value for each response to the categorical variable.<br>2. Write a Python program to display some basic statistical details like percentile, mean, standard deviation etc. of the species of ‘Iris-setosa’, ‘Iris-versicolor’ and ‘Iris-versicolor’ of iris.csv dataset.<br>Provide the codes with outputs and explain everything that you do in this step. |
| **[A4](#)** | **Data Analytics I**<br>Create a Linear Regression Model using Python/R to predict home prices using Boston Housing Dataset (https://www.kaggle.com/c/boston-housing). The Boston Housing dataset contains information about various houses in Boston through different parameters. There are 506 samples and 14 feature variables in this dataset.<br>The objective is to predict the value of prices of the house using the given features. |
| **[A5](#)** | **Data Analytics II**<br>1. Implement logistic regression using Python/R to perform classification on Social_Network_Ads.csv dataset<br>Compute Confusion matrix to find TP, FP, TN, FN, Accuracy, Error rate, Precision, Recall on the given dataset. |
| **[A6](#)** | **Data Analytics III**<br>1. Implement Simple Naïve Bayes classification algorithm using Python/R on iris.csv dataset.<br>Compute Confusion matrix to find TP, FP, TN, FN, Accuracy, Error rate, Precision, Recall on the given dataset. |
| **[A7](https://github.com/RaniK27/University-Assignments/blob/main/Semester%206/DSBDAL/A7.ipynb)** | **Text Analytics**<br>1. Extract Sample document and apply following document preprocessing methods: Tokenization, POS Tagging, stop words removal, Stemming and Lemmatization.<br>Create representation of document by calculating Term Frequency and Inverse Document Frequency. |
| **[A8](#)** | **Data Visualization I**<br>1. Use the inbuilt dataset 'titanic'. The dataset contains 891 rows and contains information about the passengers who boarded the unfortunate Titanic ship. Use the Seaborn library to see if we can find any patterns in the data.<br>Write a code to check how the price of the ticket (column name: 'fare') for each passenger is distributed by plotting a histogram |
| **[A9](#)** | **Data Visualization II**<br>1. Use the inbuilt dataset 'titanic' as used in the above problem. Plot a box plot for distribution of age with respect to each gender along with the information about whether they survived or not. (Column names : 'sex' and 'age')<br>Write observations on the inference from the above statistics. |
| **[A10](#)** | **Data Visualization III**<br>Download the Iris flower dataset or any other dataset into a DataFrame. (https://archive.ics.uci.edu/ml/datasets/Iris ). Scan the dataset and give the inference as:1. How many features are there and what are their types (e.g., numeric, nominal)?<br>2. Create a histogram for each feature in the dataset to illustrate the feature distributions.<br>3. Create a boxplot for each feature in the dataset.<br>Compare distributions and identify outliers. |
| **[B1](#)** | Write a code in JAVA for a simple WordCount application that counts the number of occurrences of each word in a given input set using the Hadoop MapReduce framework on local-standalone set-up. |
| **[B2](#)** | Design a distributed application using MapReduce which processes a log file of a system. |
| **[B3](#)** | Locate dataset (eg. sample_weather.txt) for working on weather data which reads the text input files and finds average for temperature, dew point and wind speed. |
| **[B4](#)** | Write a simple program in SCALA using Apache Spark framework. |

### [Artificial Intelligence (Laboratory Practice II)](Semester%206/LP2)

| **Experiment Folder** | **Experiment Aim** |
|:---:|---|
| **[A1](https://github.com/RaniK27/University-Assignments/blob/main/Semester%206/LP2/A1.cpp)** | Implement depth first search algorithm and Breadth First Search algorithm, Use an undirected graph and develop a recursive algorithm for searching all the vertices of a graph or tree data structure. |
| **[A2](https://github.com/RaniK27/University-Assignments/blob/main/Semester%206/LP2/A2.cpp)** | Implement A star Algorithm for any game search problem. |
| **[A3](https://github.com/RaniK27/University-Assignments/blob/main/Semester%206/LP2/A3.cpp)** | Implement Greedy search algorithm for any of the following application:<br>I. Selection Sort<br>II. Minimum Spanning Tree<br>III. Single-Source Shortest Path Problem<br>IV. Job Scheduling Problem<br>V. Prim's Minimal Spanning Tree Algorithm<br>VI. Kruskal's Minimal Spanning Tree Algorithm<br>VII. Dijkstra's Minimal Spanning Tree Algorithm |
| **[B4](#)** | Implement a solution for a Constraint Satisfaction Problem using Branch and Bound and Backtracking for n-queens problem or a graph colouring problem. |
| **[B5](#)** | Develop an elementary chatbot for any suitable customer interaction application. |
| **[C6](#)** | Implement any one of the following Expert System<br>[The Bird Identification System](https://www.amzi.com/ExpertSystemsInProlog/02usingprolog.php) |
